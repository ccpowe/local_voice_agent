from __future__ import annotations

import asyncio
import datetime
import logging
from pathlib import Path

from aioconsole import ainput
from langchain.agents import create_agent
from langchain_openai import ChatOpenAI

from .audio_utils import AudioPlayer, AudioRecorder
from .settings import Settings
from .speech_recognition import SpeechRecognizer
from .text_to_speech import TextToSpeech


def _build_chat_model(settings: Settings) -> ChatOpenAI:
    if settings.base_url:
        return ChatOpenAI(
            model_name=settings.model_name,
            openai_api_key=settings.api_key,
            openai_api_base=settings.base_url,
        )
    return ChatOpenAI(model_name=settings.model_name, openai_api_key=settings.api_key)


def _init_speech_recognizer(model_dir: Path) -> SpeechRecognizer:
    print("ðŸ”„ æ­£åœ¨åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å™¨...")
    recognizer = SpeechRecognizer(
        model_size="small",
        device="auto",
        language="zh",
        model_cache_dir=model_dir,
    )

    print("ðŸ“¥ æ­£åœ¨åŠ è½½è¯­éŸ³è¯†åˆ«æ¨¡åž‹ï¼Œè¯·ç¨å€™...")
    if recognizer.load_model():
        print("âœ… è¯­éŸ³è¯†åˆ«æ¨¡åž‹åŠ è½½æˆåŠŸ")
    else:
        print("âŒ è¯­éŸ³è¯†åˆ«æ¨¡åž‹åŠ è½½å¤±è´¥")
    return recognizer


def _init_tts(model_dir: Path, tts_out_dir: Path) -> tuple[TextToSpeech | None, bool]:
    print("ðŸ”„ æ­£åœ¨åˆå§‹åŒ–TTSè¯­éŸ³åˆæˆå™¨...")
    try:
        tts_synthesizer = TextToSpeech(
            voice="zf_001",
            speed=1.0,
            device="auto",
            model_cache_dir=model_dir,
            output_dir=tts_out_dir,
        )

        print("ðŸ“¥ æ­£åœ¨åŠ è½½TTSæ¨¡åž‹ï¼Œè¯·ç¨å€™...")
        if tts_synthesizer._load_models():
            print("âœ… TTSè¯­éŸ³åˆæˆå™¨åˆå§‹åŒ–æˆåŠŸ")
            return tts_synthesizer, True

        print("âŒ TTSæ¨¡åž‹åŠ è½½å¤±è´¥")
        return tts_synthesizer, False
    except Exception as exc:
        print(f"âš ï¸  TTSåˆå§‹åŒ–å¤±è´¥: {exc}")
        return None, False


def _print_usage(tts_available: bool) -> None:
    print("ðŸŽ¤ è¯­éŸ³åœ°ç†åˆ†æžåŠ©æ‰‹å·²å¯åŠ¨!")
    print("ðŸ’¡ ä½¿ç”¨è¯´æ˜Ž:")
    print("   - è¾“å…¥ 's' æˆ– 'speech' å¼€å§‹è¯­éŸ³è¾“å…¥")
    print("   - ç›´æŽ¥è¾“å…¥æ–‡å­—è¿›è¡Œæ–‡å­—å¯¹è¯")
    if tts_available:
        print("   - è¾“å…¥ 'tts:on' å¼€å¯è¯­éŸ³è¾“å‡ºï¼Œ'tts:off' å…³é—­è¯­éŸ³è¾“å‡º")
        print("   - è¾“å…¥ 'voice:å¥³å£°' æˆ– 'voice:ç”·å£°' åˆ‡æ¢è¯­éŸ³ç±»åž‹")
    print("   - è¾“å…¥ 'å†è§' é€€å‡ºç¨‹åº")
    print("-" * 50)


async def _record_and_transcribe(
    audio_recorder: AudioRecorder, speech_recognizer: SpeechRecognizer
) -> str | None:
    print("\nðŸŽ¤ è¯­éŸ³è¾“å…¥æ¨¡å¼")
    print("ðŸ’¡ æ“ä½œè¯´æ˜Ž: æŒ‰Enterå¼€å§‹å½•åˆ¶ï¼Œè¯´è¯åŽå†æŒ‰Enteråœæ­¢")

    audio_data = audio_recorder.record_manual()
    if audio_data is None:
        print("âŒ æœªå½•åˆ¶åˆ°éŸ³é¢‘ï¼Œè¯·é‡è¯•")
        return None

    debug_dir = Path.cwd() / "data" / "voice" / "audio_cache"
    debug_dir.mkdir(parents=True, exist_ok=True)
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    wav_path = debug_dir / f"recording_{timestamp}.wav"
    audio_recorder.save_to_wav(audio_data, wav_path)

    return speech_recognizer.transcribe_audio_file(wav_path)


async def async_main() -> None:
    logging.getLogger("httpx").setLevel(logging.WARNING)
    settings = Settings()

    audio_recorder = AudioRecorder(sample_rate=16000, channels=1)
    audio_player = AudioPlayer()

    data_dir = Path.cwd() / "data"
    model_dir = data_dir / "model"
    tts_out_dir = data_dir / "voice" / "tts_out"

    model = _build_chat_model(settings)
    agent = create_agent(model=model, tools=[], system_prompt="å¥åº·åŠ©æ‰‹å°v")

    speech_recognizer = _init_speech_recognizer(model_dir)
    tts_synthesizer, tts_available = _init_tts(model_dir, tts_out_dir)

    _print_usage(tts_available)

    tts_enabled = False

    while True:
        user_input = await ainput("è¯·è¾“å…¥ä½ çš„é—®é¢˜ (æˆ–è¾“å…¥'s'è¿›è¡Œè¯­éŸ³è¾“å…¥): ")
        normalized = user_input.strip().lower()

        match normalized:
            case "exit" | "quit" | "å†è§":
                break
            case "tts:on" if tts_available:
                tts_enabled = True
                print("ðŸ”Š è¯­éŸ³è¾“å‡ºå·²å¼€å¯")
                continue
            case "tts:off" if tts_available:
                tts_enabled = False
                print("ðŸ”‡ è¯­éŸ³è¾“å‡ºå·²å…³é—­")
                continue
            case "voice:å¥³å£°" | "voice:zf" if tts_available:
                if tts_synthesizer and tts_synthesizer.set_voice("zf_001"):
                    print("ðŸŽµ å·²åˆ‡æ¢åˆ°å¥³å£°")
                continue
            case "voice:ç”·å£°" | "voice:zm" if tts_available:
                if tts_synthesizer and tts_synthesizer.set_voice("zm_010"):
                    print("ðŸŽµ å·²åˆ‡æ¢åˆ°ç”·å£°")
                continue
            case "s" | "speech" | "è¯­éŸ³":
                transcribed = await _record_and_transcribe(
                    audio_recorder=audio_recorder,
                    speech_recognizer=speech_recognizer,
                )
                if not transcribed:
                    print("âŒ è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•")
                    continue
                print(f"ðŸ“ è¯†åˆ«ç»“æžœ: {transcribed}")
                user_input = transcribed

        print("AI: ", end="", flush=True)
        result = await agent.ainvoke(
            {"messages": [{"role": "human", "content": user_input}]},
            config={"configurable": {"thread_id": "1"}, "recursion_limit": 100},
        )

        ai_response = result["messages"][-1].content
        print(ai_response)
        print()

        if not (tts_available and tts_enabled):
            continue

        if not tts_synthesizer:
            print("TTS åˆæˆå™¨ä¸å¯ç”¨")
            continue

        if not (ai_text := str(ai_response).strip()):
            continue

        print("ðŸ”Š æ­£åœ¨ç”Ÿæˆè¯­éŸ³å›žå¤...")
        try:
            audio_file = tts_synthesizer.synthesize_long_text(ai_text)
            if not audio_file:
                print("âŒ è¯­éŸ³ç”Ÿæˆå¤±è´¥")
                continue
            print(f"ðŸŽµ è¯­éŸ³å›žå¤å·²ç”Ÿæˆ: {audio_file}")
            audio_player.play_wav_file(audio_file)
        except Exception as exc:
            print(f"âŒ TTSé”™è¯¯: {exc}")

    print("ðŸ‘‹ å†è§!")


def main() -> None:
    asyncio.run(async_main())


if __name__ == "__main__":
    main()
