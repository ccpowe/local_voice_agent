import asyncio
import datetime
import logging
import os
from pathlib import Path

from aioconsole import ainput
from dotenv import load_dotenv
from langchain.agents import create_agent
from langchain_openai import ChatOpenAI
from langgraph.checkpoint.memory import InMemorySaver

from .audio_utils import AudioPlayer, AudioRecorder
from .speech_recognition import SpeechRecognizer
from .text_to_speech import TextToSpeech

# ç¦ç”¨httpxçš„INFOæ—¥å¿—
logging.getLogger("httpx").setLevel(logging.WARNING)

load_dotenv()

audio_recorder = AudioRecorder(sample_rate=16000, channels=1)
audio_player = AudioPlayer()


# åˆå§‹åŒ–æ¨¡å‹
model = ChatOpenAI(
    model=os.getenv("MODEL_NAME"),  # type:ignore
    api_key=os.getenv("API_KEY"),  # type:ignore
    base_url=os.getenv("BASE_URL"),  # type:ignore
)


# åˆå§‹åŒ–æ£€æŸ¥ç‚¹
checkpoint = InMemorySaver()

agent = create_agent(model, tools=[], system_prompt="å¥åº·åŠ©æ‰‹å°v")

# ç»Ÿä¸€æ•°æ®ç›®å½•
DATA_DIR = Path.cwd() / "data"
MODEL_DIR = DATA_DIR / "model"
VOICE_DIR = DATA_DIR / "voice"
TTS_OUT_DIR = VOICE_DIR / "tts_out"

# åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å™¨
print("ğŸ”„ æ­£åœ¨åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å™¨...")
speech_recognizer = SpeechRecognizer(
    model_size="small",  # å¯é€‰: "tiny", "base", "small", "medium", "large"
    device="auto",  # è‡ªåŠ¨é€‰æ‹©CPUæˆ–GPU
    language="zh",  # ä¸­æ–‡è¯†åˆ«
    model_cache_dir=str(MODEL_DIR),
)

# ç«‹å³åŠ è½½è¯­éŸ³è¯†åˆ«æ¨¡å‹
print("ğŸ“¥ æ­£åœ¨åŠ è½½è¯­éŸ³è¯†åˆ«æ¨¡å‹ï¼Œè¯·ç¨å€™...")
if speech_recognizer.load_model():
    print("âœ… è¯­éŸ³è¯†åˆ«æ¨¡å‹åŠ è½½æˆåŠŸ")
else:
    print("âŒ è¯­éŸ³è¯†åˆ«æ¨¡å‹åŠ è½½å¤±è´¥")

# åˆå§‹åŒ–TTSè¯­éŸ³åˆæˆå™¨
print("ğŸ”„ æ­£åœ¨åˆå§‹åŒ–TTSè¯­éŸ³åˆæˆå™¨...")
try:
    tts_synthesizer = TextToSpeech(
        voice="zf_001",  # é»˜è®¤å¥³å£°ï¼Œå¯é€‰: zf_xxx(å¥³å£°), zm_xxx(ç”·å£°)
        speed=1.0,  # è¯­éŸ³é€Ÿåº¦
        device="auto",  # è‡ªåŠ¨é€‰æ‹©è®¾å¤‡
        model_cache_dir=str(MODEL_DIR),
        output_dir=str(TTS_OUT_DIR),
    )
    # ç«‹å³åŠ è½½TTSæ¨¡å‹
    print("ğŸ“¥ æ­£åœ¨åŠ è½½TTSæ¨¡å‹ï¼Œè¯·ç¨å€™...")
    if tts_synthesizer._load_models():
        TTS_AVAILABLE = True
        print("âœ… TTSè¯­éŸ³åˆæˆå™¨åˆå§‹åŒ–æˆåŠŸ")
    else:
        TTS_AVAILABLE = False
        print("âŒ TTSæ¨¡å‹åŠ è½½å¤±è´¥")
except Exception as e:
    tts_synthesizer = None
    TTS_AVAILABLE = False
    print(f"âš ï¸  TTSåˆå§‹åŒ–å¤±è´¥: {e}")


async def main():
    print("ğŸ¤ è¯­éŸ³åœ°ç†åˆ†æåŠ©æ‰‹å·²å¯åŠ¨!")
    print("ğŸ’¡ ä½¿ç”¨è¯´æ˜:")
    print("   - è¾“å…¥ 's' æˆ– 'speech' å¼€å§‹è¯­éŸ³è¾“å…¥")
    print("   - ç›´æ¥è¾“å…¥æ–‡å­—è¿›è¡Œæ–‡å­—å¯¹è¯")
    if TTS_AVAILABLE:
        print("   - è¾“å…¥ 'tts:on' å¼€å¯è¯­éŸ³è¾“å‡ºï¼Œ'tts:off' å…³é—­è¯­éŸ³è¾“å‡º")
        print("   - è¾“å…¥ 'voice:å¥³å£°' æˆ– 'voice:ç”·å£°' åˆ‡æ¢è¯­éŸ³ç±»å‹")
    print("   - è¾“å…¥ 'å†è§' é€€å‡ºç¨‹åº")
    print("-" * 50)

    user_input = await ainput("è¯·è¾“å…¥ä½ çš„é—®é¢˜ (æˆ–è¾“å…¥'s'è¿›è¡Œè¯­éŸ³è¾“å…¥):")

    # TTSçŠ¶æ€æ§åˆ¶
    tts_enabled = False

    while user_input.lower() != "å†è§":
        # æ£€æŸ¥TTSæ§åˆ¶å‘½ä»¤
        if TTS_AVAILABLE and user_input.lower() == "tts:on":
            tts_enabled = True
            print("ğŸ”Š è¯­éŸ³è¾“å‡ºå·²å¼€å¯")
            user_input = await ainput("è¯·è¾“å…¥ä½ çš„é—®é¢˜ (æˆ–è¾“å…¥'s'è¿›è¡Œè¯­éŸ³è¾“å…¥):")
            continue
        elif TTS_AVAILABLE and user_input.lower() == "tts:off":
            tts_enabled = False
            print("ğŸ”‡ è¯­éŸ³è¾“å‡ºå·²å…³é—­")
            user_input = await ainput("è¯·è¾“å…¥ä½ çš„é—®é¢˜ (æˆ–è¾“å…¥'s'è¿›è¡Œè¯­éŸ³è¾“å…¥):")
            continue
        elif TTS_AVAILABLE and user_input.lower() in ["voice:å¥³å£°", "voice:zf"]:
            if tts_synthesizer and tts_synthesizer.set_voice("zf_001"):
                print("ğŸµ å·²åˆ‡æ¢åˆ°å¥³å£°")
            user_input = await ainput("è¯·è¾“å…¥ä½ çš„é—®é¢˜ (æˆ–è¾“å…¥'s'è¿›è¡Œè¯­éŸ³è¾“å…¥):")
            continue
        elif TTS_AVAILABLE and user_input.lower() in ["voice:ç”·å£°", "voice:zm"]:
            if tts_synthesizer and tts_synthesizer.set_voice("zm_010"):
                print("ğŸµ å·²åˆ‡æ¢åˆ°ç”·å£°")
            user_input = await ainput("è¯·è¾“å…¥ä½ çš„é—®é¢˜ (æˆ–è¾“å…¥'s'è¿›è¡Œè¯­éŸ³è¾“å…¥):")
            continue

        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨è¯­éŸ³è¾“å…¥
        if user_input.lower() in ["s", "speech", "è¯­éŸ³"]:
            print("\nğŸ¤ è¯­éŸ³è¾“å…¥æ¨¡å¼")
            print("ğŸ’¡ æ“ä½œè¯´æ˜: æŒ‰Enterå¼€å§‹å½•åˆ¶ï¼Œè¯´è¯åå†æŒ‰Enteråœæ­¢")

            audio_data = audio_recorder.record_manual()
            file_path = None
            if audio_data is not None:
                debug_dir = Path.cwd() / "data" / "voice" / "audio_cache"
                debug_dir.mkdir(parents=True, exist_ok=True)
                timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                file_path = debug_dir / f"recording_{timestamp}.wav"
                audio_recorder.save_to_wav(audio_data, str(file_path))

            recognized_text = (
                speech_recognizer.transcribe_audio_file(str(file_path))
                if file_path is not None
                else None
            )

            if recognized_text:
                print(f"ğŸ“ è¯†åˆ«ç»“æœ: {recognized_text}")
                user_input = recognized_text
            else:
                print("âŒ è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•")
                user_input = await ainput("è¯·è¾“å…¥ä½ çš„é—®é¢˜ (æˆ–è¾“å…¥'s'è¿›è¡Œè¯­éŸ³è¾“å…¥):")
                continue

        # å¤„ç†ç”¨æˆ·è¾“å…¥ï¼ˆæ–‡å­—æˆ–è¯­éŸ³è¯†åˆ«ç»“æœï¼‰
        print("AI: ", end="", flush=True)

        result = await agent.ainvoke(
            {"messages": [{"role": "user", "content": user_input}]},
            config={"configurable": {"thread_id": "1"}, "recursion_limit": 100},
        )
        Ai_response = result["messages"][-1].content
        print(Ai_response)
        print()  # åœ¨å›ç­”ç»“æŸåæ¢è¡Œ

        # å¦‚æœå¯ç”¨äº†TTSï¼Œå°†AIå›å¤è½¬ä¸ºè¯­éŸ³
        if TTS_AVAILABLE and tts_enabled and Ai_response.strip():
            print("ğŸ”Š æ­£åœ¨ç”Ÿæˆè¯­éŸ³å›å¤...")
            try:
                if tts_synthesizer:
                    audio_file = tts_synthesizer.synthesize_long_text(
                        Ai_response.strip()
                    )
                    if audio_file:
                        print(f"ğŸµ è¯­éŸ³å›å¤å·²ç”Ÿæˆ: {audio_file}")
                        audio_player.play_wav_file(audio_file)
                    else:
                        print("âŒ è¯­éŸ³ç”Ÿæˆå¤±è´¥")
                else:
                    print("TTS åˆæˆå™¨ä¸å¯ç”¨")
            except Exception as e:
                print(f"âŒ TTSé”™è¯¯: {e}")

        user_input = await ainput("è¯·è¾“å…¥ä½ çš„é—®é¢˜ (æˆ–è¾“å…¥'s'è¿›è¡Œè¯­éŸ³è¾“å…¥):")


if __name__ == "__main__":
    asyncio.run(main())
