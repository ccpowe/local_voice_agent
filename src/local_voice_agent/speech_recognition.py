"""
è¯­éŸ³è¯†åˆ«æ¨¡å— - åŸºäºfaster-whisper
"""

import logging
import tempfile
import wave
from pathlib import Path
from typing import Optional

import numpy as np
import torch
from faster_whisper import WhisperModel

from .audio_utils import AudioRecorder

# å°è¯•å¯¼å…¥ç¹ç®€è½¬æ¢åº“
try:
    from zhconv import convert

    ZHCONV_AVAILABLE = True
except ImportError:
    ZHCONV_AVAILABLE = False
    logging.warning("zhconvåº“æœªå®‰è£…ï¼Œæ— æ³•è¿›è¡Œç¹ç®€è½¬æ¢")


WHISPER_CONFIG = {
    "model_size": "small",
    "device": "auto",
    "compute_type": "float16",
    "language": "zh",
}
AUDIO_CONFIG = {"sample_rate": 16000, "channels": 1}
PATH_CONFIG = {"model_cache_dir": Path.cwd() / "data" / "model"}
LOG_CONFIG = {"level": "INFO"}

# é…ç½®æ—¥å¿—
logging.basicConfig(level=getattr(logging, LOG_CONFIG.get("level", "INFO")))
logger = logging.getLogger(__name__)


class SpeechRecognizer:
    """è¯­éŸ³è¯†åˆ«å™¨ï¼Œä½¿ç”¨faster-whisperè¿›è¡Œä¸­æ–‡è¯­éŸ³è¯†åˆ«"""

    def __init__(
        self,
        model_size: Optional[str] = None,
        device: Optional[str] = None,
        compute_type: Optional[str] = None,
        language: Optional[str] = None,
        model_cache_dir: Optional[str] = None,
    ):
        """
        åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å™¨

        Args:
            model_size: æ¨¡å‹å¤§å° ("tiny", "base", "small", "medium", "large")
            device: è®¾å¤‡ç±»å‹ ("cpu", "cuda", "auto")
            compute_type: è®¡ç®—ç±»å‹ ("float16", "float32", "int8")
            language: è¯­è¨€ä»£ç  ("zh"è¡¨ç¤ºä¸­æ–‡)
            model_cache_dir: æŒ‡å®šæ¨¡å‹ä¸‹è½½ç›®å½•ï¼ˆé»˜è®¤: ./data/modelï¼‰
        """
        # ä½¿ç”¨é…ç½®æ–‡ä»¶çš„é»˜è®¤å€¼
        self.model_size = model_size or WHISPER_CONFIG.get("model_size", "small")
        self.device = device or WHISPER_CONFIG.get("device", "auto")
        self.compute_type = compute_type or WHISPER_CONFIG.get(
            "compute_type", "float32"
        )
        self.language = language or WHISPER_CONFIG.get("language", "zh")
        self.model = None

        # åˆå§‹åŒ–éŸ³é¢‘å½•åˆ¶å™¨ï¼Œä½¿ç”¨é…ç½®å‚æ•°
        self.audio_recorder = AudioRecorder(
            sample_rate=AUDIO_CONFIG.get("sample_rate", 16000),
            channels=AUDIO_CONFIG.get("channels", 1),
        )

        # æ¨¡å‹ä¸‹è½½è·¯å¾„
        base_cache_dir = (
            Path(model_cache_dir) if model_cache_dir else PATH_CONFIG["model_cache_dir"]
        )
        self.model_path = base_cache_dir / "whisper"
        self.model_path.mkdir(parents=True, exist_ok=True)

        logger.info(f"åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å™¨: æ¨¡å‹={self.model_size}, è®¾å¤‡={self.device}")

    def _convert_to_simplified(self, text: str) -> str:
        """
        å°†ç¹ä½“ä¸­æ–‡è½¬æ¢ä¸ºç®€ä½“ä¸­æ–‡

        Args:
            text: è¾“å…¥æ–‡æœ¬

        Returns:
            ç®€ä½“ä¸­æ–‡æ–‡æœ¬
        """
        if not ZHCONV_AVAILABLE or not text:
            return text

        try:
            # ä½¿ç”¨zhconvè¿›è¡Œç¹ç®€è½¬æ¢
            simplified = convert(text, "zh-cn")
            if simplified != text:
                logger.info(f"ç¹ç®€è½¬æ¢: {text} -> {simplified}")
            return simplified
        except Exception as e:
            logger.warning(f"ç¹ç®€è½¬æ¢å¤±è´¥: {e}")
            return text

    def load_model(self) -> bool:
        """åŠ è½½Whisperæ¨¡å‹"""
        try:
            logger.info(f"æ­£åœ¨åŠ è½½Whisperæ¨¡å‹: {self.model_size}")

            # å¦‚æœè®¾å¤‡æ˜¯autoï¼Œè‡ªåŠ¨é€‰æ‹©
            if self.device == "auto":
                device = "cuda" if torch.cuda.is_available() else "cpu"
                logger.info(f"è‡ªåŠ¨é€‰æ‹©è®¾å¤‡: {device}")
            else:
                device = self.device

            self.model = WhisperModel(
                model_size_or_path=self.model_size,
                device=device,
                compute_type=self.compute_type,
                download_root=str(self.model_path),
            )

            logger.info("Whisperæ¨¡å‹åŠ è½½æˆåŠŸ")
            return True

        except Exception as e:
            logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False

    def transcribe_audio_data(
        self, audio_data: np.ndarray, sample_rate: int = 16000
    ) -> Optional[str]:
        """
        è½¬å½•éŸ³é¢‘æ•°æ®

        Args:
            audio_data: éŸ³é¢‘æ•°æ® (numpy array)
            sample_rate: é‡‡æ ·ç‡

        Returns:
            è¯†åˆ«çš„æ–‡æœ¬ï¼Œå¤±è´¥è¿”å›None
        """
        if self.model is None:
            if not self.load_model():
                return None

        try:
            # å°†éŸ³é¢‘æ•°æ®ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_file:
                temp_filename = temp_file.name
                self.audio_recorder.save_to_wav(audio_data, temp_filename)

            # ä½¿ç”¨faster-whisperè¿›è¡Œè½¬å½•
            segments, info = self.model.transcribe(
                temp_filename,
                language=self.language,
                beam_size=5,
                best_of=5,
                temperature=0.0,
                condition_on_previous_text=False,
            )

            # åˆå¹¶æ‰€æœ‰æ®µè½çš„æ–‡æœ¬
            full_text = ""
            for segment in segments:
                full_text += segment.text

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            Path(temp_filename).unlink(missing_ok=True)

            # æ¸…ç†æ–‡æœ¬å¹¶è¿›è¡Œç¹ç®€è½¬æ¢
            text = full_text.strip()
            if text:
                # è¿›è¡Œç¹ç®€è½¬æ¢
                simplified_text = self._convert_to_simplified(text)
                logger.info(f"è¯†åˆ«ç»“æœ: {simplified_text}")
                return simplified_text
            else:
                logger.warning("æœªè¯†åˆ«åˆ°æœ‰æ•ˆæ–‡æœ¬")
                return None

        except Exception as e:
            logger.error(f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {e}")
            return None

    def record_and_transcribe(self) -> Optional[str]:
        """
        å½•åˆ¶éŸ³é¢‘å¹¶è¿›è¡Œè¯­éŸ³è¯†åˆ« - ä½¿ç”¨æ‰‹åŠ¨æ§åˆ¶æ¨¡å¼

        Returns:
            è¯†åˆ«çš„æ–‡æœ¬ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            import numpy as np
            import sounddevice as sd

            print("ğŸ¤ å‡†å¤‡å¼€å§‹å½•åˆ¶...")
            input("æŒ‰ Enter å¼€å§‹å½•åˆ¶: ")

            print("ğŸ”´ å½•åˆ¶ä¸­... æŒ‰ Enter åœæ­¢å½•åˆ¶")

            # å½•åˆ¶å‚æ•°
            sample_rate = 16000
            channels = 1
            recording = True
            audio_data = []

            def audio_callback(indata, frames, time, status):
                if recording:
                    audio_data.append(indata.copy())

            # å¼€å§‹å½•åˆ¶æµ
            with sd.InputStream(
                samplerate=sample_rate,
                channels=channels,
                callback=audio_callback,
                dtype=np.float32,
            ):
                input()  # ç­‰å¾…ç”¨æˆ·æŒ‰Enteråœæ­¢

            recording = False
            print("â¹ï¸ å½•åˆ¶åœæ­¢!")

            if not audio_data:
                logger.warning("æœªå½•åˆ¶åˆ°éŸ³é¢‘æ•°æ®")
                return None

            # åˆå¹¶éŸ³é¢‘æ•°æ®å¹¶è½¬æ¢æ ¼å¼
            audio_float = np.concatenate(audio_data, axis=0)
            audio_int16 = (audio_float * 32767).astype(np.int16).flatten()

            duration = len(audio_int16) / sample_rate
            logger.info(f"å½•åˆ¶å®Œæˆï¼ŒéŸ³é¢‘é•¿åº¦: {duration:.2f}ç§’")

            # ä¿å­˜å½•éŸ³æ–‡ä»¶ç”¨äºè°ƒè¯•
            import datetime

            debug_dir = Path.cwd() / "data" / "voice" / "debug_recordings"
            debug_dir.mkdir(parents=True, exist_ok=True)

            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            debug_filename = debug_dir / f"recording_{timestamp}.wav"

            try:
                # æ·»åŠ è°ƒè¯•ä¿¡æ¯
                logger.info(
                    f"éŸ³é¢‘æ•°æ®ç±»å‹: {audio_int16.dtype}, å½¢çŠ¶: {audio_int16.shape}, èŒƒå›´: [{audio_int16.min()}, {audio_int16.max()}]"
                )

                with wave.open(debug_filename, "wb") as wf:
                    wf.setnchannels(channels)
                    wf.setsampwidth(2)  # 16-bit
                    wf.setframerate(sample_rate)
                    wf.writeframes(audio_int16.tobytes())

                logger.info(f"ğŸµ å½•éŸ³å·²ä¿å­˜åˆ°: {debug_filename}")

                # éªŒè¯ä¿å­˜çš„æ–‡ä»¶å¤§å°
                file_size = debug_filename.stat().st_size
                logger.info(f"ğŸ“ æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
            except Exception as e:
                logger.warning(f"ä¿å­˜å½•éŸ³æ–‡ä»¶å¤±è´¥: {e}")
                import traceback

                logger.warning(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")

            # è¿›è¡Œè¯­éŸ³è¯†åˆ«
            return self.transcribe_audio_data(audio_int16, sample_rate)

        except Exception as e:
            logger.error(f"å½•åˆ¶å’Œè¯†åˆ«å¤±è´¥: {e}")
            import traceback

            logger.error(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return None

    def transcribe_audio_file(self, audio_file_path: str) -> Optional[str]:
        """
        è½¬å½•éŸ³é¢‘æ–‡ä»¶

        Args:
            audio_file_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„

        Returns:
            è¯†åˆ«çš„æ–‡æœ¬ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            # ç¡®ä¿æ¨¡å‹å·²åŠ è½½
            if self.model is None:
                if not self.load_model():
                    return None

            if self.model is None:
                logger.error("æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œè½¬å½•")
                return None

            # ç›´æ¥ä½¿ç”¨Whisperå¤„ç†éŸ³é¢‘æ–‡ä»¶ï¼Œæ”¯æŒå¤šç§æ ¼å¼
            segments, info = self.model.transcribe(
                audio_file_path,
                language=self.language,
                beam_size=5,
                best_of=5,
                temperature=0.0,
                condition_on_previous_text=False,
            )

            # è®°å½•è¯­è¨€æ£€æµ‹ä¿¡æ¯
            logger.info(
                f"æ£€æµ‹åˆ°è¯­è¨€: {info.language} (ç½®ä¿¡åº¦: {info.language_probability:.2f})"
            )

            # åˆå¹¶æ‰€æœ‰æ®µè½çš„æ–‡æœ¬
            full_text = ""
            segment_count = 0
            for segment in segments:
                full_text += segment.text
                segment_count += 1
                logger.debug(
                    f"æ®µè½ {segment_count}: [{segment.start:.2f}s -> {segment.end:.2f}s] {segment.text}"
                )

            logger.info(f"è½¬å½•å®Œæˆï¼Œå…± {segment_count} ä¸ªæ®µè½")

            # æ¸…ç†æ–‡æœ¬å¹¶è¿›è¡Œç¹ç®€è½¬æ¢
            text = full_text.strip()
            if text:
                # è¿›è¡Œç¹ç®€è½¬æ¢
                simplified_text = self._convert_to_simplified(text)
                logger.info(f"è¯†åˆ«ç»“æœ: {simplified_text}")
                return simplified_text
            else:
                logger.warning("æœªè¯†åˆ«åˆ°æœ‰æ•ˆæ–‡æœ¬")
                return None

        except Exception as e:
            logger.error(f"éŸ³é¢‘æ–‡ä»¶è½¬å½•å¤±è´¥: {e}")
            return None

    def __del__(self):
        """ææ„å‡½æ•°ï¼Œæ¸…ç†èµ„æº"""
        if hasattr(self, "model") and self.model is not None:
            del self.model
